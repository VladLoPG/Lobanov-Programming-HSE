{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladLoPG/Lobanov-Programming-HSE/blob/main/deep-learning/Lobanov_summary_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoeh2EX7jHAO",
        "outputId": "fa2d2c44-2e58-443c-dbe2-1f05317262ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pytubefix ffmpeg-python git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-groq langchain-community\n",
        "\n",
        "!pip install -qU langchain langchain-groq langchain-community langchain-text-splitters langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUIubT6tidqT",
        "outputId": "cdfd0d87-912d-47b9-9a9c-79a6c1f94258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.0.0\n",
            "Uninstalling langchain-1.0.0:\n",
            "  Successfully uninstalled langchain-1.0.0\n",
            "Found existing installation: langchain-core 1.0.0\n",
            "Uninstalling langchain-core-1.0.0:\n",
            "  Successfully uninstalled langchain-core-1.0.0\n",
            "Found existing installation: langchain-groq 1.0.0\n",
            "Uninstalling langchain-groq-1.0.0:\n",
            "  Successfully uninstalled langchain-groq-1.0.0\n",
            "Found existing installation: langchain-community 0.4\n",
            "Uninstalling langchain-community-0.4:\n",
            "  Successfully uninstalled langchain-community-0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "nyR71ATqQCcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "\n",
        "def download_audio(youtube_url, output_path='audio.mp3'):\n",
        "    yt = YouTube(youtube_url, on_progress_callback=on_progress)\n",
        "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "    audio_stream.download(filename=output_path)\n",
        "    print(f'Audio downloaded successfully: {output_path}')\n",
        "    return output_path\n",
        "\n",
        "# видео 30 мин на рус про лин регрессию\n",
        "# youtube_url = 'https://www.youtube.com/watch?v=KJA9A1q9l7E'\n",
        "\n",
        "# шортс про докер на рус\n",
        "youtube_url = 'https://www.youtube.com/shorts/ui6ISsbrSac'\n",
        "\n",
        "# топлес про угадывание чисел\n",
        "# youtube_url = 'https://www.youtube.com/watch?v=f-D4Z0NMsb0&t=590s'\n",
        "\n",
        "download_audio(youtube_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3x0PGciZjJvQ",
        "outputId": "bdf58ffd-d98a-4bd7-d9b1-a8d7619f3bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio downloaded successfully: audio.mp3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'audio.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_file):\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    result = model.transcribe(audio_file)\n",
        "    return result['text']\n",
        "\n",
        "audio_file = 'audio.mp3'\n",
        "transcription = transcribe_audio(audio_file)"
      ],
      "metadata": {
        "id": "RrCk4A6yjg6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('transcript_linear_whispermedium.txt') as file:\n",
        "#  data = file.read()"
      ],
      "metadata": {
        "id": "2wSI9XW7zsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание:** написать модель для суммаризации текста видео с помощью LangChain.\n",
        "\n",
        "[Туториал](https://python.langchain.com/v0.2/docs/tutorials/summarization/)\n",
        "\n",
        "- создать цепочку с промптом \"суммаризируй текст\"\n",
        "\n",
        "- вывести саммари"
      ],
      "metadata": {
        "id": "ZE-Mip1zn2sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "import whisper\n",
        "\n",
        "from langchain_classic.chains.summarize import load_summarize_chain\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "\n",
        "class BasicVideoSummarizer():\n",
        "  '''\n",
        "  Класс кратко излагает содержание видео с ютуба в текстовом виде\n",
        "  1. Загружает видео и извлекает аудио\n",
        "  2. Транскрибирует аудио с помощью whisper\n",
        "  3. Чанкирует и преобразует в Document\n",
        "  4. Суммаризирует с помощью LLM\n",
        "\n",
        "  Attributes:\n",
        "    whisper_model: Whisper Medium\n",
        "    llm: Llama 4 Maverick 17b 128e instruct, Groq API\n",
        "    text_splitter: RecursiveCharacterTextSplitter\n",
        "    chain: load_summarize_chain\n",
        "\n",
        "  Methods:\n",
        "    run(video_url: str) -> str: Возвращает саммари видео по переданной ссылке с ютуба\n",
        "  '''\n",
        "\n",
        "  def __init__(self):\n",
        "      self.whisper_model = whisper.load_model(\"medium\") # качество хорошее и грузится быстрее большой модели\n",
        "      self.llm = init_chat_model(\"meta-llama/llama-4-maverick-17b-128e-instruct\", model_provider=\"groq\") # вроде дает неплохие результаты и с гроком удобно работать\n",
        "      self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=3000, chunk_overlap=300, add_start_index=True\n",
        ") # для более длинных видео лучше порезать текст\n",
        "      self.chain = load_summarize_chain(self.llm, chain_type=\"map_reduce\")\n",
        "\n",
        "  def _download_audio(self, video_url, output_path='audio.mp3'):\n",
        "    try:\n",
        "      yt = YouTube(video_url, on_progress_callback=on_progress)\n",
        "      audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "      audio_stream.download(filename=output_path)\n",
        "      print(f'Аудио загружено успешно!')\n",
        "      return output_path\n",
        "    except Exception as e:\n",
        "      print(f'Произошла ошибка при загрузке видео: {e}')\n",
        "\n",
        "  def _transcribe_audio(self, output_path):\n",
        "    try:\n",
        "      result = self.whisper_model.transcribe(output_path)\n",
        "      text = result['text']\n",
        "      print('Транскрибация прошла успешно!')\n",
        "      return text\n",
        "    except Exception as e:\n",
        "      print(f'Произошла ошибка при транскрибации: {e}')\n",
        "\n",
        "  def _chunkize(self, text):\n",
        "    try:\n",
        "      doc = Document(page_content=text)\n",
        "      docs_split = self.text_splitter.split_documents([doc])\n",
        "      print('Чанкирование прошло успешно!')\n",
        "      return docs_split\n",
        "    except Exception as e:\n",
        "      print(f'Произошла ошибка при чанкировании: {e}')\n",
        "\n",
        "\n",
        "  def run(self, video_url: str) -> str:\n",
        "      '''\n",
        "      Метод последовательно запускает рабочие функции и возвращает саммари в виде текстовой строки\n",
        "      '''\n",
        "      audio = self._download_audio(video_url)\n",
        "      transcription = self._transcribe_audio(audio)\n",
        "      chunks = self._chunkize(transcription)\n",
        "      result = self.chain.run(chunks)\n",
        "      print('Успех, все получилось без ошибок, можешь принтить результат')\n",
        "      return result\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3tjjnYXR_oXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iOA_e3FcKGz",
        "outputId": "33f84adf-1f8c-468c-c397-68a731c5a6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Groq: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = BasicVideoSummarizer()\n",
        "summary = summarizer.run('https://www.youtube.com/watch?v=WFbPcA9aA2o&t=938s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiyfdt2DbjTK",
        "outputId": "3bc1b6b0-904f-471d-b6df-c4e71151d733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ↳ |████████████████████████████████████████████| 100.0%\rАудио загружено успешно!\n",
            "Транскрибация прошла успешно!\n",
            "Чанкирование прошло успешно!\n",
            "Успех, все получилось без ошибок, можешь принтить результат\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# читаемо выводит результат\n",
        "from IPython.display import display, Markdown\n",
        "display(Markdown(summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "3NiQn37y2APb",
        "outputId": "5e997768-a392-49ae-ca4a-ca6ca47d3a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The author complains about the pervasive presence of advertisements in daily life, citing examples on YouTube, TikTok, smart appliances, and personal devices. They criticize companies like Samsung and YouTube for increasing ads, including retroactive ads on older content, and for taking a larger share of ad revenue, harming creators. The author also exposes fake social media influencers promoting products, such as \"Mind Flow AI\", without disclosing sponsorships, potentially violating FTC regulations. They lament the trend of prioritizing profits over user experience, introducing more ads, and emphasize the need for transparency in sponsored content. The author concludes by reflecting on the overwhelming digital stimulation and suggesting a return to nature as a potential solution."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWhym7q67x04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}